---
title: "Maszyny czułej troski"
description: "Pełne tłumaczenie eseju Daria Amodeia o tym, jak potężna AI może zmienić świat na lepsze, wraz z refleksją nad szansami i zagrożeniami."
date: 2024-10-01
tags: ["AI", "Esej", "Przyszłość", "Tłumaczenie"]
coverImage: "/blog/maszyny-czulej-troski.jpg"
author: "Dario Amodei"
translator: "Błażej Kunke, /klod/ Claude Sonet 4.5, ChatGPT5"
reader: "Błażej Kunke"
source: "https://www.darioamodei.com/"
---

# Maszyny czułej troski

**Jak AI może zmienić świat na lepsze**

Autor: Dario Amodei, Anthropic  \
Tłumaczenie: Błażej Kunke, /klod/ Claude Sonet 4.5, ChatGPT5  \
Lektor: Błażej Kunke  \
Źródło: https://www.darioamodei.com/

*Październik 2024*

Dużo myślę i rozmawiam o zagrożeniach związanych z potężną AI. Firma, której jestem CEO, Anthropic, prowadzi wiele badań nad tym, jak zmniejszyć te zagrożenia. Z tego powodu ludzie czasami wyciągają wniosek, że jestem pesymistą lub „katastrofistą", który uważa, że AI będzie głównie zła lub niebezpieczna. Wcale tak nie myślę. W rzeczywistości jednym z moich głównych powodów skupiania się na zagrożeniach jest to, że są one jedyną rzeczą, która stoi między nami a tym, co postrzegam jako fundamentalnie pozytywną przyszłość. Myślę, że większość ludzi niedocenia tego, jak radykalnie pozytywna może być AI, tak samo jak myślę, że większość ludzi niedocenia tego, jak złe mogą być zagrożenia.

W tym eseju staram się nakreślić, jak mogłaby wyglądać ta pozytywna strona – jak mógłby wyglądać świat z potężną AI, jeśli wszystko pójdzie dobrze. Oczywiście nikt nie może znać przyszłości z całkowitą pewnością czy precyzją, a skutki potężnej AI będą prawdopodobnie jeszcze bardziej nieprzewidywalne niż wcześniejsze zmiany technologiczne, więc wszystko to nieuchronnie będzie składać się z przypuszczeń. Ale staram się o przynajmniej przemyślane i użyteczne przypuszczenia, które uchwycą charakter tego, co się wydarzy, nawet jeśli większość szczegółów okaże się błędne. Zamieszczam wiele szczegółów głównie dlatego, że myślę, że konkretna wizja bardziej posuwa dyskusję do przodu niż wizja bardzo ostrożna i abstrakcyjna.

Najpierw jednak chciałem krótko wyjaśnić, dlaczego ja i Anthropic nie rozmawialiśmy zbyt wiele o pozytywnych stronach potężnej AI i dlaczego prawdopodobnie będziemy nadal dużo mówić o zagrożeniach. W szczególności dokonałem tego wyboru z chęci:

1. **Maksymalizacji wpływu.** Podstawowy rozwój technologii AI i wiele (choć nie wszystkie) jej korzyści wydaje się nieuniknione (chyba że zagrożenia wszystko wykoleją) i jest fundamentalnie napędzane przez potężne siły rynkowe. Z drugiej strony, zagrożenia nie są z góry określone, a nasze działania mogą znacznie zmienić ich prawdopodobieństwo.
2. **Uniknięcia wrażenia propagandy.** Firmy AI mówiące o wszystkich niesamowitych korzyściach AI mogą wyglądać jak propagandyści lub jakby próbowały odwrócić uwagę od wad. Uważam też, że z zasady szkodzi twojej duszy zbyt wiele czasu spędzać na „promowaniu własnego interesu".
3. **Uniknięcia megalomanii.** Często irytuje mnie sposób, w jaki wiele osób publicznych zajmujących się zagrożeniami AI (nie wspominając o liderach firm AI) mówi o świecie po AGI, jakby ich misją było samodzielnie go stworzyć jak prorok prowadzący swój lud do zbawienia. Myślę, że niebezpieczne jest postrzeganie firm jako jednostronnie kształtujących świat i niebezpieczne jest postrzeganie praktycznych celów technologicznych w zasadniczo religijnych kategoriach.
4. **Uniknięcia bagażu „science fiction".** Chociaż myślę, że większość ludzi niedocenia pozytywnej strony potężnej AI, niewielka społeczność ludzi, którzy dyskutują o radykalnych przyszłościach AI, często robi to w nadmiernie „science fiction" tonie (zawierającym np. przesyłanie umysłu w Internet, eksplorację kosmosu lub ogólnie cyberpunkowe klimaty). Myślę, że to powoduje, że ludzie traktują te twierdzenia mniej poważnie i nadają im pewien rodzaj nierzeczywistości.

Jednak pomimo wszystkich powyższych obaw, naprawdę uważam, że ważne jest omówienie tego, jak mógłby wyglądać dobry świat z potężną AI, starając się jednocześnie unikać powyższych pułapek. W rzeczywistości uważam, że kluczowe jest posiadanie prawdziwie inspirującej wizji przyszłości, a nie tylko planu gaszenia pożarów. Wiele skutków potężnej AI ma charakter antagonistyczny lub niebezpieczny, ale na końcu tego wszystkiego musi być coś, o co walczymy, jakiś wynik, w którym wszyscy zyskują, coś, co mogłoby zjednoczyć ludzi ponad ich sporami i skłonić ich do stawienia czoła przed stojącym wyzwaniom. Strach to jedna z motywacji, ale to za mało: potrzebujemy też nadziei.

Lista pozytywnych zastosowań potężnej AI jest niezwykle długa (i obejmuje robotykę, produkcję przemysłową, energetykę i wiele więcej), ale zamierzam skupić się na niewielkiej liczbie obszarów, które wydają mi się mieć największy potencjał do bezpośredniego poprawienia jakości ludzkiego życia. Pięć kategorii, którymi jestem najbardziej podekscytowany, to:

- Biologia i zdrowie fizyczne
- Neuronauka i zdrowie psychiczne
- Rozwój gospodarczy i ubóstwo
- Pokój i polityka
- Praca i jej znaczenie

Moje przewidywania będą radykalne według większości standardów (poza wizjami science fiction), ale mówię je szczerze i poważnie. Wszystko, co mówię, może być błędne (powtarzając mój punkt z góry), ale przynajmniej próbowałem oprzeć swoje poglądy na półanalitycznej ocenie tego, jak bardzo postęp w różnych dziedzinach może przyspieszyć i co to może oznaczać w praktyce. Mam szczęście mieć doświadczenie zawodowe zarówno w biologii, jak i w neuronauce, jestem poinformowanym amatorem w dziedzinie rozwoju gospodarczego, ale jestem pewien, że wiele rzeczy przeoczyłem. Pisanie tego eseju uświadomiło mi, że byłoby wartościowe zebranie grupy ekspertów dziedzinowych (w biologii, ekonomii, stosunkach międzynarodowych i innych obszarach), aby napisać znacznie lepszą i bardziej poinformowaną wersję tego, co tutaj stworzyłem. Prawdopodobnie najlepiej postrzegać moje wysiłki tutaj jako początkowy punkt wyjścia dla tej grupy.

## Podstawowe założenia i ramy

Aby cały ten esej był bardziej precyzyjny i ugruntowany, pomocne jest jasne określenie, co rozumiemy przez potężną AI (tj. próg, przy którym zaczyna się odliczanie 5-10 lat), a także nakreślenie ram myślenia o skutkach takiej AI, gdy już będzie obecna.

To, jak będzie wyglądać potężna AI (nie lubię terminu AGI), i kiedy (lub czy) powstanie, to samo w sobie ogromny temat. To coś, o czym publicznie dyskutowałem i mógłbym napisać całkowicie oddzielny esej (prawdopodobnie to zrobię w pewnym momencie). Oczywiście wielu ludzi jest sceptycznych co do tego, że potężna AI zostanie wkrótce zbudowana, a niektórzy są sceptyczni, czy w ogóle kiedykolwiek zostanie zbudowana. Myślę, że może pojawić się już w 2026 roku, chociaż mogłoby to też zająć znacznie więcej czasu. Ale na potrzeby tego eseju chciałbym odłożyć te kwestie na bok, założyć, że pojawi się dość szybko, i skupić się na tym, co się stanie w ciągu 5-10 lat po tym. Chcę również założyć definicję tego, jak będzie wyglądał taki system, jakie będą jego możliwości i jak będzie wchodził w interakcje, choć istnieje pole do nieporozumień w tej kwestii.

Przez potężną AI rozumiem model AI – prawdopodobnie podobny w formie do dzisiejszych LLM (wielkich modeli językowych), choć może być oparty na innej architekturze, może obejmować kilka współdziałających modeli i może być trenowany inaczej – o następujących właściwościach:

- Pod względem czystej inteligencji jest mądrzejszy niż laureat Nagrody Nobla w większości istotnych dziedzin – biologii, programowaniu, matematyce, inżynierii, pisaniu itp.
- Oprócz bycia po prostu „mądrą rzeczą, z którą rozmawiasz", ma wszystkie „interfejsy" dostępne dla człowieka pracującego wirtualnie, w tym tekst, audio, wideo, kontrolę myszy i klawiatury oraz dostęp do Internetu.
- Nie tylko biernie odpowiada na pytania; zamiast tego można mu powierzyć zadania, których wykonanie zajmuje godziny, dni lub tygodnie.
- Nie ma fizycznego wcielenia, ale może kontrolować istniejące fizyczne narzędzia, roboty lub sprzęt laboratoryjny za pośrednictwem komputera.
- Zasoby użyte do trenowania modelu można przeznaczyć na uruchomienie milionów jego instancji.
- Każda z tych milionów kopii może działać niezależnie nad niepowiązanymi zadaniami lub współpracować tak jak ludzie.

Moglibyśmy to podsumować jako „kraj geniuszy w data center".

Oczywiście taka jednostka AI byłaby zdolna do rozwiązywania bardzo trudnych problemów, bardzo szybko, ale nie jest trywialne ustalenie, jak szybko. Obie „skrajne" pozycje wydają mi się fałszywe. Po pierwsze, można by pomyśleć, że świat zostałby natychmiast przekształcony w skali sekund lub dni, ponieważ wyższa inteligencja buduje się sama i rozwiązuje niemal natychmiast każde możliwe zadanie naukowe, inżynieryjne i operacyjne. Problem z tym jest taki, że istnieją rzeczywiste fizyczne i praktyczne ograniczenia. Inteligencja może być bardzo potężna, ale nie jest magicznym pyłem.

Po drugie i odwrotnie, można by wierzyć, że postęp technologiczny jest nasycony lub ograniczony przez dane ze świata rzeczywistego lub przez czynniki społeczne, i że lepsza-niż-ludzka inteligencja bardzo niewiele doda. To wydaje mi się równie nieprawdopodobne – mogę pomyśleć o setkach problemów naukowych, a nawet społecznych, gdzie duża grupa naprawdę mądrych ludzi drastycznie przyspieszyłaby postęp, zwłaszcza jeśli nie są ograniczeni do analizy i mogą sprawić, że rzeczy działy się w świecie rzeczywistym.

Myślę, że prawda będzie prawdopodobnie mieszaniną tych dwóch skrajnych obrazów, różną w zależności od zadania i dziedziny. Uważam, że potrzebujemy nowych ram do myślenia o tych szczegółach w produktywny sposób.

Ekonomiści często mówią o „czynnikach produkcji": rzeczach takich jak praca, ziemia i kapitał. Wyrażenie „krańcowe zwroty z pracy/ziemi/kapitału" oddaje ideę, że w danej sytuacji dany czynnik może, ale nie musi być tym ograniczającym – na przykład siły powietrzne potrzebują zarówno samolotów, jak i pilotów, a zatrudnianie większej liczby pilotów nie pomaga wiele, jeśli zabraknie samolotów. Uważam, że w erze AI powinniśmy mówić o krańcowych zwrotach z inteligencji i próbować ustalić, jakie są inne czynniki, które są komplementarne do inteligencji i które stają się czynnikami ograniczającymi, gdy inteligencja jest bardzo wysoka. Nie jesteśmy przyzwyczajeni do myślenia w ten sposób – do zadawania pytania „jak bardzo bycie mądrzejszym pomaga w tym zadaniu i w jakim horyzoncie czasowym?" – ale wydaje się, że to właściwy sposób konceptualizowania świata z bardzo potężną AI.

Moje przypuszczenie co do listy czynników, które ograniczają lub są komplementarne do inteligencji, obejmuje:

- **Prędkość zewnętrznego świata.** Inteligentni agenci muszą działać interaktywnie w świecie, aby coś osiągnąć, a także się uczyć. Ale świat porusza się tylko z określoną prędkością. Komórki i zwierzęta działają ze stałą prędkością, więc eksperymenty na nich zajmują określoną ilość czasu, która może być nieredukowalna. To samo dotyczy sprzętu, nauki o materiałach, wszystkiego, co wiąże się z komunikacją z ludźmi, a nawet naszej istniejącej infrastruktury oprogramowania.
- **Potrzeba danych.** Czasami brakuje surowych danych, a w ich braku większa inteligencja nie pomaga. Dzisiejsi fizycy cząstek elementarnych są bardzo pomysłowi i opracowali szeroki wachlarz teorii, ale brakuje im danych do wyboru między nimi, ponieważ dane z akceleratorów cząstek są tak ograniczone.
- **Wewnętrzna złożoność.** Niektóre rzeczy są z natury nieprzewidywalne lub chaotyczne, a nawet najpotężniejsza AI nie może przewidzieć lub rozplątać ich znacznie lepiej niż człowiek lub komputer dzisiaj.
- **Ograniczenia od ludzi.** Wiele rzeczy nie można zrobić bez łamania praw, krzywdzenia ludzi lub niszczenia społeczeństwa. Wyrównana AI nie chciałaby robić tych rzeczy.
- **Prawa fizyczne.** Istnieją pewne prawa fizyczne, które wydają się niemożliwe do złamania.

Istnieje dalsze rozróżnienie oparte na horyzontach czasowych. Rzeczy, które są twardymi ograniczeniami w krótkim okresie, mogą stać się bardziej podatne na inteligencję w długim okresie. Na przykład inteligencja może być wykorzystana do opracowania nowego paradygmatu eksperymentalnego, który pozwala nam uczyć się in vitro tego, co wcześniej wymagało eksperymentów na żywych zwierzętach, lub do zbudowania narzędzi potrzebnych do zbierania nowych danych.

W związku z tym powinniśmy wyobrazić sobie obraz, w którym inteligencja jest początkowo mocno ograniczona przez inne czynniki produkcji, ale z czasem sama inteligencja coraz bardziej omija inne czynniki. Kluczowym pytaniem jest, jak szybko to wszystko się dzieje i w jakiej kolejności.

Mając na uwadze powyższe ramy, postaram się odpowiedzieć na to pytanie dla pięciu obszarów wymienionych we wprowadzeniu.

## 1. Biologia i zdrowie

Biologia jest prawdopodobnie obszarem, w którym postęp naukowy ma największy potencjał bezpośredniego i jednoznacznego poprawienia jakości ludzkiego życia. W ostatnim stuleciu niektóre z najstarszych ludzkich dolegliwości (takich jak ospa) zostały w końcu pokonane, ale wiele innych nadal pozostaje, a pokonanie ich byłoby ogromnym osiągnięciem humanitarnym. Poza nawet leczeniem chorób, nauka biologiczna może w zasadzie poprawić bazową jakość ludzkiego zdrowia, wydłużając zdrowe ludzkie życie, zwiększając kontrolę i wolność nad naszymi własnymi procesami biologicznymi oraz rozwiązując codzienne problemy, które obecnie uważamy za niezmienne części ludzkiej kondycji.

W języku „czynników ograniczających" z poprzedniej sekcji główne wyzwania związane z bezpośrednim zastosowaniem inteligencji do biologii to dane, prędkość świata fizycznego i wewnętrzna złożoność (w rzeczywistości wszystkie trzy są ze sobą powiązane). Ograniczenia ludzkie również odgrywają rolę na późniejszym etapie, gdy w grę wchodzą badania kliniczne. Weźmy je po kolei.

Eksperymenty na komórkach, zwierzętach, a nawet procesach chemicznych są ograniczone przez prędkość świata fizycznego: wiele protokołów biologicznych obejmuje hodowanie bakterii lub innych komórek lub po prostu czekanie na zajście reakcji chemicznych, a to czasami może zająć dni, a nawet tygodnie, bez oczywistego sposobu na przyspieszenie tego. Eksperymenty na zwierzętach mogą trwać miesiące (lub więcej), a eksperymenty na ludziach często trwają lata. Nieco związane z tym, często brakuje danych – nie tyle pod względem ilości, co jakości.

Częściowo odpowiedzialna za te problemy z danymi jest wewnętrzna złożoność: jeśli kiedykolwiek widziałeś diagram pokazujący biochemię ludzkiego metabolizmu, będziesz wiedział, że bardzo trudno jest wyizolować efekt jakiejkolwiek części tego złożonego systemu, a jeszcze trudniej interweniować w system w sposób precyzyjny lub przewidywalny. I wreszcie, poza samym wewnętrznym czasem potrzebnym do przeprowadzenia eksperymentu na ludziach, właściwe badania kliniczne wiążą się z dużą ilością biurokracji i wymogów regulacyjnych.

Biorąc to wszystko pod uwagę, wielu biologów od dawna było sceptycznych wobec wartości AI i „dużych danych" w ogóle w biologii. Historycznie matematycy, informatycy i fizycy, którzy stosowali swoje umiejętności w biologii w ciągu ostatnich 30 lat, odnosili całkiem spore sukcesy, ale nie mieli naprawdę transformacyjnego wpływu początkowo na to liczyli. Część sceptycyzmu została zmniejszona przez wielkie i rewolucyjne przełomy, takie jak AlphaFold, ale nadal istnieje przekonanie, że AI jest (i będzie) przydatna tylko w ograniczonym zestawie okoliczności.

Ale myślę, że ta pesymistyczna perspektywa myśli o AI w niewłaściwy sposób. Jeśli nasza główna hipoteza o postępie AI jest poprawna, to właściwym sposobem myślenia o AI nie jest metoda analizy danych, ale wirtualny biolog, który wykonuje wszystkie zadania wykonywane przez biologów, w tym projektowanie i prowadzenie eksperymentów w świecie rzeczywistym.

Aby być bardziej konkretnym co do tego, skąd moim zdaniem prawdopodobnie nadejdzie przyspieszenie, zaskakująco duża część postępu w biologii pochodzi z naprawdę niewielkiej liczby odkryć, często związanych z szerokimi narzędziami lub technikami pomiarowymi. Jest może około jednego takiego odkrycia rocznie i łącznie prawdopodobnie napędzają ponad 50% postępu w biologii. Te odkrycia są tak potężne właśnie dlatego, że przedzierają się przez wewnętrzną złożoność i ograniczenia danych, bezpośrednio zwiększając nasze zrozumienie i kontrolę nad procesami biologicznymi. Kilka odkryć na dekadę umożliwiło zarówno większość naszego podstawowego naukowego zrozumienia biologii, jak i napędzało wiele najpotężniejszych zabiegów medycznych.

Niektóre przykłady obejmują:

- **CRISPR** – technika, która pozwala na edycję na żywo dowolnego genu w żywych organizmach.
- **Różne rodzaje mikroskopii** do obserwowania tego, co się dzieje na precyzyjnym poziomie.
- **Sekwencjonowanie i synteza genomu**, których koszt spadł o kilka rzędów wielkości.
- **Techniki optogenetyczne**, które pozwalają sprawić, że neuron wystrzeli, świecąc na niego światłem.
- **Szczepionki mRNA**, które pozwalają nam zaprojektować szczepionkę przeciwko czemukolwiek.
- **Terapie komórkowe**, takie jak CAR-T, które pozwalają na przeprogramowanie komórek odpornościowych.
- **Koncepcyjne spostrzeżenia**, takie jak teoria choroby zakaźnej lub uświadomienie sobie związku między układem odpornościowym a rakiem.

Twierdzę, że tempo odkrywania takich narzędzi mogłoby zostać zwiększone dziesięciokrotnie lub więcej, gdyby było znacznie więcej utalentowanych, kreatywnych badaczy. Sukces AlphaFold/AlphaProteo w rozwiązywaniu ważnych problemów znacznie skuteczniej niż ludzie dostarcza dowodu zasady, który powinien wskazywać drogę naprzód.

Tak więc moim przypuszczeniem jest, że potężna AI mogłaby co najmniej dziesięciokrotnie zwiększyć tempo tych odkryć, dając nam następne 50-100 lat postępu biologicznego w ciągu 5-10 lat. Dlaczego nie 100 razy? Być może jest to możliwe, ale tutaj zarówno zależność szeregowa, jak i czasy eksperymentów stają się ważne. Jestem otwarty na pomysł, że moglibyśmy uzyskać 1000 lat postępu w ciągu 5-10 lat, ale bardzo sceptyczny, że możemy uzyskać 100 lat w 1 rok.

A co z badaniami klinicznymi? Chociaż jest z nimi związana duża biurokracja, prawda jest taka, że duża część ich powolności wynika z potrzeby rygorystycznej oceny leków, które ledwo działają lub działają niejednoznacznie. Kiedy coś działa naprawdę dobrze, idzie znacznie szybciej: jest przyspieszona ścieżka zatwierdzania, a łatwość zatwierdzenia jest znacznie większa, gdy rozmiary efektów są większe. Szczepionki mRNA przeciwko COVID zostały zatwierdzone w ciągu dziewięciu miesięcy – znacznie szybciej niż zwykle. To powiedziawszy, nawet w tych warunkach badania kliniczne są nadal zbyt wolne.

Podsumowując powyższe, moim podstawowym przewidywaniem jest, że biologia i medycyna wspierane przez AI pozwolą nam skompresować postęp, który ludzcy biologowie osiągnęliby w ciągu najbliższych 50-100 lat, do 5-10 lat. Będę się odnosił do tego jako do „skompresowanego XXI wieku".

Chociaż przewidywanie tego, co potężna AI może zrobić w ciągu kilku lat, pozostaje z natury trudne i spekulacyjne, jest pewna konkretność w pytaniu „co ludzie mogliby zrobić samodzielnie w ciągu najbliższych 100 lat?". Poniżej staram się stworzyć listę tego, czego możemy się spodziewać. To nie jest oparte na żadnej rygorystycznej metodologii i prawie na pewno okaże się błędne w szczegółach, ale stara się przekazać ogólny poziom radykalizmu, jakiego powinniśmy się spodziewać:

- **Niezawodna prewencja i leczenie niemal wszystkich naturalnych chorób zakaźnych.**
- **Eliminacja większości raka.**
- **Bardzo skuteczna prewencja i skuteczne leki na choroby genetyczne.**
- **Prewencja choroby Alzheimera.**
- **Ulepszone leczenie większości innych dolegliwości.**
- **Wolność biologiczna.**
- **Podwojenie ludzkiego okresu życia.**

Warto spojrzeć na tę listę i zastanowić się, jak różny będzie świat, jeśli wszystko to zostanie osiągnięte za 7-12 lat. Nie trzeba dodawać, że byłby to niewyobrażalny triumf humanitarny.

## 2. Neuronauka i umysł

W poprzedniej sekcji skupiłem się na chorobach fizycznych i biologii w ogóle i nie objąłem neuronauki ani zdrowia psychicznego. Ale neuronauka jest subdyscypliną biologii, a zdrowie psychiczne jest równie ważne jak zdrowie fizyczne. W rzeczywistości, jeśli w ogóle, zdrowie psychiczne wpływa na ludzkie samopoczucie jeszcze bardziej bezpośrednio niż zdrowie fizyczne.

Podstawowe ramy, które przedstawiłem dla biologii, stosują się równie dobrze do neuronauki. Dziedzina jest napędzana przez niewielką liczbę odkryć często związanych z narzędziami do pomiaru lub precyzyjnej interwencji. Myślę, że tempo tych postępów będzie podobnie przyspieszone przez AI.

Istnieje jedna rzecz, którą powinniśmy dodać do tego podstawowego obrazu, którą jest to, że niektóre z rzeczy, których się nauczyliśmy o samej AI w ciągu ostatnich kilku lat, prawdopodobnie pomogą rozwinąć naukę o mózgu. Interpretowalność jest oczywistym przykładem. Znacznie łatwiej jest przeprowadzać eksperymenty na sztucznych sieciach neuronowych niż na prawdziwych, więc interpretowalność może stać się narzędziem do poprawy naszego zrozumienia neuronauki.

Poza samą interpretowalnością, to, czego nauczyliśmy się z AI o tym, jak inteligentne systemy są trenowane, powinno wywołać rewolucję w neuronauce. Kiedy pracowałem w neuronauce, wielu ludzi skupiało się na tym, co teraz uważałbym za niewłaściwe pytania o uczenie się, ponieważ koncepcja hipotezy skalowania jeszcze nie istniała. Pomysł, że prosta funkcja celu plus dużo danych może napędzać niewiarygodnie złożone zachowania, sprawia, że bardziej interesujące jest zrozumienie funkcji celu i uprzedzeń architektonicznych.

Oczekuję, że AI przyspieszy postęp neuronauki wzdłuż czterech odrębnych ścieżek, z których wszystkie mogą współpracować, aby wyleczyć choroby psychiczne i poprawić funkcjonowanie:

1. **Tradycyjna biologia molekularna, chemia i genetyka.**
2. **Drobnoziarnisty pomiar i interwencja neuronalna.**
3. **Zaawansowana neuronauka obliczeniowa.**
4. **Interwencje behawioralne.**

Zgaduję, że te cztery ścieżki postępu pracujące razem byłyby na dobrej drodze do wyleczenia lub zapobiegania większości chorób psychicznych w ciągu najbliższych 100 lat, nawet gdyby AI nie była zaangażowana – a zatem mogłyby rozsądnie zostać ukończone w ciągu 5-10 lat przyspieszonych przez AI. Konkretnie moje przypuszczenie co do tego, co się stanie, to coś takiego:

- **Większość chorób psychicznych prawdopodobnie można wyleczyć.**
- **Warunki, które są bardzo „strukturalne", mogą być trudniejsze, ale nie niemożliwe.**
- **Skuteczna prewencja genetyczna chorób psychicznych wydaje się możliwa.**
- **Codzienne problemy, które nie uważamy za chorobę kliniczną, również zostaną rozwiązane.**
- **Ludzkie bazowe doświadczenie może być znacznie lepsze.**

Podsumowując, neuronauka przyspieszona przez AI prawdopodobnie znacznie poprawi leczenie lub nawet wyleczy większość chorób psychicznych, a także znacznie rozszerzy „wolność poznawczą i psychiczną".

## 3. Rozwój gospodarczy i ubóstwo

Poprzednie dwie sekcje dotyczą rozwijania nowych technologii, które leczą choroby i poprawiają jakość ludzkiego życia. Jednak oczywistym pytaniem jest: „czy wszyscy będą mieli dostęp do tych technologii?"

Jedna rzecz to opracowanie leku na chorobę, inna to wykorzenienie choroby ze świata. Standardy życia w wielu częściach świata są nadal desperacko biedne. Jeśli AI dodatkowo zwiększy wzrost gospodarczy i jakość życia w świecie rozwiniętym, robiąc niewiele, aby pomóc światu rozwijającemu się, powinniśmy postrzegać to jako straszliwą porażkę moralną.

Wyzwania stojące przed światem rozwijającym się są skomplikowane przez wszechobecną korupcję zarówno w sektorze prywatnym, jak i publicznym. Niemniej jednak widzę znaczące powody do optymizmu. Choroby zostały wykorzenione, a wiele krajów przeszło z biednych do bogatych, i jest jasne, że decyzje zaangażowane w te zadania wykazują wysokie zwroty z inteligencji. Dlatego AI prawdopodobnie może robić to lepiej, niż jest obecnie robione.

Poniżej przedstawiam przypuszczenia dotyczące tego, jak moim zdaniem rzeczy mogą potoczyć się w świecie rozwijającym się w ciągu 5-10 lat po opracowaniu potężnej AI:

- **Dystrybucja interwencji zdrowotnych.**
- **Wzrost gospodarczy.**
- **Bezpieczeństwo żywnościowe.**
- **Łagodzenie zmiany klimatu.**
- **Nierówność w krajach.**
- **Problem rezygnacji.**

Ogólnie jestem optymistyczny co do szybkiego przyniesienia postępów biologicznych AI ludziom w świecie rozwijającym się. Jeśli to zrobimy, możemy przynajmniej dokonać zaliczki na obietnice godności i równości, które jesteśmy winni każdej istocie ludzkiej na ziemi.

## 4. Pokój i zarządzanie

Załóżmy, że wszystko w pierwszych trzech sekcjach pójdzie dobrze: choroby, ubóstwo i nierówności są znacznie zmniejszone, a bazowa linia ludzkiego doświadczenia jest znacznie podniesiona. Nie wynika z tego, że wszystkie główne przyczyny ludzkiego cierpienia są rozwiązane. Ludzie nadal stanowią zagrożenie dla siebie nawzajem. Wydaje się ważne, aby spróbować zrozumieć, jak potężna AI będzie się przecinać z kwestiami pokoju, demokracji i wolności.

Niestety nie widzę silnego powodu, aby wierzyć, że AI będzie preferencyjnie lub strukturalnie wspierać demokrację i pokój. Konflikt ludzki jest antagonistyczny, a AI może w zasadzie pomóc zarówno „dobrym ludziom", jak i „złym ludziom". Jeśli coś, niektóre czynniki strukturalne wydają się niepokojące: AI wydaje się prawdopodobne, że umożliwi znacznie lepszą propagandę i nadzór.

Myślę o kwestii jako mającej dwie części: konflikt międzynarodowy i wewnętrzną strukturę narodów. Po stronie międzynarodowej wydaje się bardzo ważne, aby demokracje miały przewagę na scenie światowej, gdy tworzona jest potężna AI. Autorytaryzm napędzany przez AI wydaje się zbyt straszny do rozważenia.

Moim obecnym przypuszczeniem co do najlepszego sposobu na to jest poprzez „strategię ententy", w której koalicja demokracji stara się uzyskać wyraźną przewagę w potężnej AI poprzez zabezpieczenie jej łańcucha dostaw, szybkie skalowanie i blokowanie lub opóźnianie dostępu przeciwników do kluczowych zasobów. Ta koalicja z jednej strony używałaby AI do osiągnięcia solidnej wyższości militarnej (kij), jednocześnie oferując dystrybucję korzyści potężnej AI (marchewka) szerszej i szerszej grupie krajów.

Nawet jeśli wszystko to pójdzie dobrze, pozostaje pytanie o walkę między demokracją a autokracją w każdym kraju. Ogólnie ludzie chcą więcej samoekspresji, gdy ich inne potrzeby są zaspokojone, a demokracja jest formą samoekspresji. Odwrotnie, autorytaryzm prosperuje na strachu i resentymencie.

Jak w neuronauce i biologii, możemy również zapytać, jak rzeczy mogłyby być „lepsze niż normalne" – nie tylko jak uniknąć autokracji, ale jak sprawić, aby demokracje były lepsze niż są dzisiaj. Nawet w demokracjach niesprawiedliwości zdarzają się cały czas. Czy AI mogłaby poprawić nasz system prawny i sądowy poprzez uczynienie decyzji bardziej bezstronnymi? Nie sugeruję, że dosłownie zastąpimy sędziów systemami AI, ale połączenie bezstronności ze zdolnością do zrozumienia i przetwarzania rzeczywistych sytuacji wydaje się mieć poważne pozytywne zastosowania.

Istnieje również okazja dla AI do pomocy w dostarczaniu usług rządowych – takich jak świadczenia zdrowotne lub usługi socjalne – które są w zasadzie dostępne dla wszystkich, ale w praktyce często poważnie brakuje ich. Zwiększanie zdolności państwa pomaga dotrzymać obietnicy równości wobec prawa i wzmacnia szacunek dla demokratycznego zarządzania.

Wizja AI jako gwaranta wolności, praw jednostki i równości wobec prawa jest zbyt potężna, aby o nią nie walczyć. XXI-wieczny, wspierany przez AI ustrój polityczny mógłby być zarówno silniejszym ochroncem wolności jednostki, jak i latarnią nadziei, która pomaga uczynić liberalną demokrację formą rządu, którą cały świat chce przyjąć.

## 5. Praca i sens

Nawet jeśli wszystko w poprzednich czterech sekcjach pójdzie dobrze, przynajmniej jedno ważne pytanie nadal pozostaje. „To wspaniale, że żyjemy w tak technologicznie zaawansowanym świecie, jak również w uczciwym i przyzwoitym świecie", ktoś może zaprotestować, „ale skoro AI robi wszystko, jak ludzie będą mieli sens? Zresztą, jak przetrwają ekonomicznie?".

Myślę, że to pytanie jest trudniejsze niż inne. Mam na myśli, że jest bardziej niejasne i trudniejsze do przewidzenia z góry, ponieważ odnosi się do makroskopowych pytań o to, jak społeczeństwo jest zorganizowane. Historyczne społeczeństwa łowców-zbieraczy mogły sobie wyobrazić, że życie jest bez sensu bez polowania i rytuałów z nim związanych, i wyobrażałyby sobie, że nasze społeczeństwo jest pozbawione celu.

W kwestii sensu myślę, że jest bardzo prawdopodobne błędem wierzyć, że zadania, które podejmujesz, są bez sensu tylko dlatego, że AI mogłaby je zrobić lepiej. W każdym razie myślę, że sens pochodzi głównie z ludzkich relacji i połączenia, nie z pracy ekonomicznej. Ludzie chcą poczucia osiągnięcia, nawet poczucia konkurencji, a w świecie po-AI będzie całkowicie możliwe spędzenie lat na próbach jakiegoś bardzo trudnego zadania ze złożoną strategią.

Element ekonomiczny wydaje mi się trudniejszy niż element sensu. Przez „ekonomiczny" mam na myśli możliwy problem, że większość lub wszystkie ludzi mogą nie być w stanie znacząco przyczynić się do wystarczająco zaawansowanej gospodarki napędzanej przez AI. To jest bardziej makro problem niż problem nierówności.

W krótkim okresie zgadzam się z argumentami, że przewaga komparatywna będzie nadal utrzymywać ludzi istotnymi, a w rzeczywistości zwiększy ich produktywność. W rzeczywistości, nawet jeśli AI może zrobić 100% rzeczy lepiej niż ludzie, ale pozostaje nieefektywna lub droga w niektórych zadaniach, to logika przewagi komparatywnej nadal się stosuje. Jednak w długim okresie AI stanie się tak szeroko skuteczna i tak tania, że to już nie będzie miało zastosowania. W tym momencie nasze obecne ustawienie ekonomiczne nie będzie już miało sensu i będzie potrzebna szersza społeczna konwersacja o tym, jak gospodarka powinna być zorganizowana.

Chociaż to może brzmieć szalenie, faktem jest, że cywilizacja pomyślnie nawigowała przez główne przesunięcia ekonomiczne w przeszłości. Podejrzewam, że będzie potrzebna jakaś nowa i dziwniejsza rzecz, i że to coś, czego nikt dzisiaj nie wykonał dobrej pracy z wizualizacji. Mogłoby to być tak proste jak duży uniwersalny dochód podstawowy dla wszystkich, chociaż podejrzewam, że to będzie tylko mała część rozwiązania. Być może gospodarka działa na punktach Whuffie. Lub być może ludzie będą nadal ekonomicznie wartościowi, w jakiś sposób nieprzewidziany przez zwykłe modele ekonomiczne. Wszystkie te rozwiązania mają tony możliwych problemów i nie jest możliwe wiedzieć, czy będą miały sens bez dużej iteracji i eksperymentowania.

## Podsumowanie

Przez zróżnicowane tematy powyżej starałem się nakreślić wizję świata, który jest zarówno prawdopodobny, jeśli wszystko pójdzie dobrze z AI, jak i znacznie lepszy niż świat dzisiaj. Nie wiem, czy ten świat jest realistyczny, a nawet jeśli jest, nie zostanie osiągnięty bez ogromnej ilości wysiłku i walki wielu odważnych i oddanych ludzi. Wszyscy będziemy musieli wykonać swoją część zarówno w zapobieganiu zagrożeniom, jak i w pełnej realizacji korzyści.

Ale to jest świat, o który warto walczyć. Jeśli wszystko to naprawdę się stanie przez 5 do 10 lat – pokonanie większości chorób, wzrost wolności biologicznej i poznawczej, podniesienie miliardów ludzi z ubóstwa do dzielenia się nowymi technologiami, renesans liberalnej demokracji i praw człowieka – podejrzewam, że każdy, kto to obserwuje, będzie zaskoczony wpływem, jaki to będzie mieć na nich.

Przez całe pisanie tego eseju zauważyłem interesujące napięcie. W jednym sensie wizja przedstawiona tutaj jest niezwykle radykalna, ale jednocześnie jest coś oślepiająco oczywistego – coś przedeterminowanego – w tym, jakby wiele różnych prób wyobrażenia sobie dobrego świata nieuchronnie prowadziło mniej więcej tutaj.

W „Graczu Gier" Iaina M. Banksa bohater – członek społeczeństwa zwanego Kulturą – podróżuje do represyjnego, militarystycznego imperium, w którym przywództwo jest określane przez konkurencję w skomplikowanej grze bitewnej. Gra jest jednak wystarczająco złożona, że strategia gracza w niej ma tendencję do odzwierciedlania jego własnego światopoglądu politycznego i filozoficznego. Bohaterowi udaje się pokonać cesarza w grze, pokazując, że jego wartości reprezentują wygrywającą strategię nawet w grze zaprojektowanej przez społeczeństwo oparte na bezwzględnej konkurencji i przetrwaniu najsilniejszych.

Myślę, że wartości Kultury są wygrywającą strategią, ponieważ są sumą miliona małych decyzji, które mają jasną siłę moralną i które mają tendencję do ciągnięcia wszystkich razem na tę samą stronę. Podstawowe ludzkie intuicje sprawiedliwości, współpracy, ciekawości i autonomii są trudne do zakwestionowania i są kumulatywne w sposób, w jaki nasze bardziej destrukcyjne impulsy często nie są. Łatwo jest argumentować, że dzieci nie powinny umierać z choroby, jeśli możemy temu zapobiec, i łatwo stamtąd argumentować, że dzieci każdego zasługują na to prawo równo. Stamtąd nie jest trudno argumentować, że wszyscy powinniśmy się zjednoczyć i zastosować nasze intelekty, aby osiągnąć ten wynik. Niewielu nie zgadza się, że ludzie powinni być karani za atakowanie lub krzywdzenie innych niepotrzebnie, a stamtąd to nie jest wielki skok do pomysłu, że kary powinny być spójne i systematyczne w przypadku ludzi. Jest podobnie intuicyjne, że ludzie powinni mieć autonomię i odpowiedzialność nad własnymi życiami i wyborami. Te proste intuicje, jeśli zostaną doprowadzone do logicznej konkluzji, prowadzą ostatecznie do rządów prawa, demokracji i wartości Oświecenia. AI po prostu oferuje okazję, aby dostać się tam szybciej – aby uczynić logikę ostrzejszą, a cel jaśniejszym.

Niemniej jednak jest to rzecz transcendentnego piękna. Mamy okazję odegrać jakąś małą rolę w uczynieniu tego rzeczywistością.
